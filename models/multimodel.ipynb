{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(file_name):\n",
    "    file_path = os.path.join(datasets_folder, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        return pd.read_csv(file_path)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = \"../datasets\"\n",
    "file_name = \"tupi_binary.csv\"\n",
    "df_tupi = read_csv_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>researcher</th>\n",
       "      <th>year</th>\n",
       "      <th>aggressive</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848623693028e+18</td>\n",
       "      <td>@user @user @user quanto vc pagava na época da...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848623777333e+18</td>\n",
       "      <td>@user os árabes já vão lhes chutar do país ??</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848960585394e+18</td>\n",
       "      <td>@user @user @user @user @user tem que desenhar...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65849012716374e+18</td>\n",
       "      <td>@user @user chola mais gado. e se não quiser p...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65849018793945e+18</td>\n",
       "      <td>michele micheque nao tinha cartao do bolsonaro...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                    id  \\\n",
       "0  twitter  1.65848623693028e+18   \n",
       "1  twitter  1.65848623777333e+18   \n",
       "2  twitter  1.65848960585394e+18   \n",
       "3  twitter  1.65849012716374e+18   \n",
       "4  twitter  1.65849018793945e+18   \n",
       "\n",
       "                                                text      researcher  year  \\\n",
       "0  @user @user @user quanto vc pagava na época da...  oliveira et al  2023   \n",
       "1      @user os árabes já vão lhes chutar do país ??  oliveira et al  2023   \n",
       "2  @user @user @user @user @user tem que desenhar...  oliveira et al  2023   \n",
       "3  @user @user chola mais gado. e se não quiser p...  oliveira et al  2023   \n",
       "4  michele micheque nao tinha cartao do bolsonaro...  oliveira et al  2023   \n",
       "\n",
       "   aggressive  hate  \n",
       "0           1     1  \n",
       "1           1     1  \n",
       "2           1     1  \n",
       "3           1     1  \n",
       "4           1     1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tupi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'text_column' is the column containing the text in your dataset\n",
    "text_column = 'text'\n",
    "\n",
    "# List of terms to exclude\n",
    "exclude_terms = {\n",
    "    'desse', 'aí', 'n', 'https', '@', 'user', 'link', '#', '??', '!!', '_:', '.:', '!:', '? ?', '! !', '_ :', '! :', '? :', 'rt',\n",
    "    'ta', 'tá', 'q', 'pq', 'ter', 'pra', 'vcs', 'todos', 'aí', 'nunca', 'fala', 'ver', 'coisa', 'desse', 'todo', 'quer', 'agora', 'faz',\n",
    "    'n', 'fazer', 'ainda', 'dia', 'pode', 'tudo', 'nao', 'nada', 'vc', 'vai', 'pq', 'por que', 'porque', 'eh', 'ne', 'né', 'é', 'p',\n",
    "    'la', 'lá', 'ai', 'aí', 'to', 'tô','sobre','fez','pois','onde','aqui','pro','dar','ficar','fica','d','[]'\n",
    "}\n",
    "\n",
    "import re\n",
    "\n",
    "# Function to preprocess text by excluding terms\n",
    "def preprocess_text(text):\n",
    "    # Split the text into words using regular expression\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    # Exclude terms in a case-insensitive manner\n",
    "    filtered_words = [word for word in words if word.lower() not in exclude_terms]\n",
    "\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_text\n",
    "\n",
    "# Apply the preprocessing function to the 'text_column' in your DataFrame\n",
    "df_tupi['text'] = df_tupi['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame size: 43668\n",
      "Train DataFrame size: 34934\n",
      "Test DataFrame size: 8734\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "# Assuming 'aggressive' is your target variable\n",
    "\n",
    "# Stratified sampling\n",
    "train_df, test_df = train_test_split(df_tupi, test_size=0.2, stratify=df_tupi['hate'], random_state=42)\n",
    "\n",
    "# Display the sizes of the resulting DataFrames\n",
    "print(f\"Original DataFrame size: {len(df_tupi)}\")\n",
    "print(f\"Train DataFrame size: {len(train_df)}\")\n",
    "print(f\"Test DataFrame size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights\n",
    "pos = len(train_df.query(\"hate==1\"))\n",
    "neg = len(train_df.query(\"hate==0\"))\n",
    "weight_for_0 = (1 / neg) * (len(train_df) / 2.0)\n",
    "weight_for_1 = (1 / pos) * (len(train_df) / 2.0) * 1.15\n",
    "relative_weight = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Training Data:\n",
      "    00   03   08   10  100   11   12   13   14   15  ...  vôlei   às  água  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "\n",
      "   época  ódio  ótimo  última  último  única  único  \n",
      "0    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "1    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "2    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "3    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "4    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 1500 columns]\n",
      "TF-IDF Test Data:\n",
      "    00   03   08   10  100   11   12   13   14   15  ...  vôlei   às  água  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0.0   \n",
      "\n",
      "   época  ódio  ótimo  última  último  única  único  \n",
      "0    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "1    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "2    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "3    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "4    0.0   0.0    0.0     0.0     0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 1500 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TfidfVectorizer with optional parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    lowercase=False,\n",
    "    analyzer=\"word\",\n",
    "    norm=\"l2\",\n",
    "    sublinear_tf=True,\n",
    "    min_df=2,\n",
    "    max_features=1500, \n",
    "    ngram_range=(1, 2),)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Optional: Convert the TF-IDF matrices to Pandas DataFrames for better understanding\n",
    "tfidf_train_df = pd.DataFrame(X_train_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_test_df = pd.DataFrame(X_test_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Optional: Display the TF-IDF DataFrames\n",
    "print(\"TF-IDF Training Data:\")\n",
    "print(tfidf_train_df.head())\n",
    "\n",
    "print(\"TF-IDF Test Data:\")\n",
    "print(tfidf_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'aggressive' is your target variable\n",
    "y_train = train_df['hate']\n",
    "y_test = test_df['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=relative_weight,\n",
    "    min_samples_split=5,  # Adjusted\n",
    "    max_depth=15,  # Adjusted\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "dt_pred = dt_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=relative_weight,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=150,  # Adjusted\n",
    "    max_depth=20,  # Adjusted\n",
    "    oob_score=True,\n",
    "    )\n",
    "\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "rf_pred = rf_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoriareis/miniconda3/envs/tupi-env/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC\n",
    "svc_model = LinearSVC(\n",
    "    penalty=\"l2\",\n",
    "    loss=\"squared_hinge\",\n",
    "    dual=True,\n",
    "    tol=1e-4,\n",
    "    C=0.5,  # Adjusted\n",
    "    multi_class=\"crammer_singer\",\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=0.8,  # Adjusted\n",
    "    class_weight=relative_weight,\n",
    "    random_state=42,\n",
    "    max_iter=1500,  # Adjusted\n",
    ")\n",
    "svc_model.fit(X_train_tfidf, y_train)\n",
    "svc_pred = svc_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoriareis/miniconda3/envs/tupi-env/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "dt_pred = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "rf_pred = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Linear SVC\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "svc_model.fit(X_train_tfidf, y_train)\n",
    "svc_pred = svc_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Evaluation:\n",
      "Accuracy: 0.8595\n",
      "Precision: 0.3972\n",
      "Recall: 0.3235\n",
      "F1 Score: 0.3566\n",
      "\n",
      "Random Forest Evaluation:\n",
      "Accuracy: 0.8904\n",
      "Precision: 0.6451\n",
      "Recall: 0.1989\n",
      "F1 Score: 0.3040\n",
      "\n",
      "Linear SVC Evaluation:\n",
      "Accuracy: 0.8910\n",
      "Precision: 0.6486\n",
      "Recall: 0.2055\n",
      "F1 Score: 0.3121\n",
      "ROC AUC Score: 0.8025\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "def evaluate_model(model_name, y_true, y_pred, y_prob=None):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
    "    \n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    if roc_auc is not None:\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Decision Tree\n",
    "evaluate_model(\"Decision Tree\", y_test, dt_pred)\n",
    "\n",
    "# Random Forest\n",
    "evaluate_model(\"Random Forest\", y_test, rf_pred)\n",
    "\n",
    "# Linear SVC\n",
    "svc_prob = svc_model.decision_function(X_test_tfidf)  # Linear SVC does not have predict_proba, but decision_function can be used for ROC AUC\n",
    "evaluate_model(\"Linear SVC\", y_test, svc_pred, svc_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tupi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
