{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from collections import Counter\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "\n",
    "datasets_folder = \"../datasets\"\n",
    "file_name = \"tupi_binary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Construct the full path to the CSV file\n",
    "csv_file_path = os.path.join(datasets_folder, file_name)\n",
    "\n",
    "# Check if the file exists before attempting to read it\n",
    "if os.path.isfile(csv_file_path):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>researcher</th>\n",
       "      <th>year</th>\n",
       "      <th>aggressive</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848623693028e+18</td>\n",
       "      <td>@user @user @user quanto vc pagava na época da...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848623777333e+18</td>\n",
       "      <td>@user os árabes já vão lhes chutar do país ??</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848960585394e+18</td>\n",
       "      <td>@user @user @user @user @user tem que desenhar...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65849012716374e+18</td>\n",
       "      <td>@user @user chola mais gado. e se não quiser p...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65849018793945e+18</td>\n",
       "      <td>michele micheque nao tinha cartao do bolsonaro...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                    id  \\\n",
       "0  twitter  1.65848623693028e+18   \n",
       "1  twitter  1.65848623777333e+18   \n",
       "2  twitter  1.65848960585394e+18   \n",
       "3  twitter  1.65849012716374e+18   \n",
       "4  twitter  1.65849018793945e+18   \n",
       "\n",
       "                                                text      researcher  year  \\\n",
       "0  @user @user @user quanto vc pagava na época da...  oliveira et al  2023   \n",
       "1      @user os árabes já vão lhes chutar do país ??  oliveira et al  2023   \n",
       "2  @user @user @user @user @user tem que desenhar...  oliveira et al  2023   \n",
       "3  @user @user chola mais gado. e se não quiser p...  oliveira et al  2023   \n",
       "4  michele micheque nao tinha cartao do bolsonaro...  oliveira et al  2023   \n",
       "\n",
       "   aggressive  hate  \n",
       "0           1     1  \n",
       "1           1     1  \n",
       "2           1     1  \n",
       "3           1     1  \n",
       "4           1     1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_string = \"Author: <a href=\\\"https://huggingface.co/ruanchaves\\\">Ruan Chaves Rodrigues</a>. Read more about our <a href=\\\"https://github.com/ruanchaves/eplm\\\">research on the evaluation of Portuguese language models</a>.\"\n",
    "\n",
    "app_title = \"Offensive Language Detection (Detecção de Linguagem Ofensiva)\"\n",
    "\n",
    "app_description = \"\"\"\n",
    "This app detects offensive language in Portuguese text using multiple models. You can either introduce your own sentences by filling in the \"Text\" field or click on one of the examples provided below.\n",
    "(Este aplicativo detecta linguagem ofensiva em texto em português usando vários modelos. Introduza suas próprias frases preenchendo o campo \"Text\", ou clique em um dos exemplos fornecidos abaixo.)\n",
    "\"\"\"\n",
    "\n",
    "app_examples = [[text] for text in df['text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_textbox_component_description = \"\"\"\n",
    "This box will display offensive language detection results based on the average score of multiple models.\n",
    "(Esta caixa exibirá resultados da detecção de linguagem ofensiva com base na pontuação média de vários modelos.)\n",
    "\"\"\"\n",
    "\n",
    "output_json_component_description = { \"breakdown\": \"\"\"\n",
    "This box presents a detailed breakdown of the evaluation for each model.\n",
    "\"\"\",\n",
    "\"detalhamento\": \"\"\"\n",
    "(Esta caixa apresenta um detalhamento da avaliação para cada modelo.)\n",
    "\"\"\" }\n",
    "\n",
    "short_score_descriptions = {\n",
    "   0: \"Not offensive\",\n",
    "   1: \"Offensive\"\n",
    "}\n",
    "\n",
    "score_descriptions = {\n",
    "    0: \"This text is not offensive.\",\n",
    "    1: \"This text is offensive.\",\n",
    "}\n",
    "\n",
    "score_descriptions_pt = {\n",
    "    1: \"(Este texto é ofensivo.)\",\n",
    "    0: \"(Este texto não é ofensivo.)\",\n",
    "}\n",
    "\n",
    "model_list = [\n",
    "    \"ruanchaves/mdeberta-v3-base-hatebr\",\n",
    "    \"ruanchaves/bert-base-portuguese-cased-hatebr\",\n",
    "    \"ruanchaves/bert-large-portuguese-cased-hatebr\",\n",
    "]\n",
    "\n",
    "user_friendly_name = {\n",
    "    \"ruanchaves/mdeberta-v3-base-hatebr\": \"mDeBERTa-v3 (HateBR)\",\n",
    "    \"ruanchaves/bert-base-portuguese-cased-hatebr\": \"BERTimbau base (HateBR)\",\n",
    "    \"ruanchaves/bert-large-portuguese-cased-hatebr\": \"BERTimbau large (HateBR)\",\n",
    "}\n",
    "\n",
    "reverse_user_friendly_name = { v:k for k,v in user_friendly_name.items() }\n",
    "\n",
    "user_friendly_name_list = list(user_friendly_name.values())\n",
    "\n",
    "model_array = []\n",
    "\n",
    "for model_name in model_list:\n",
    "    row = {}\n",
    "    row[\"name\"] = model_name\n",
    "    row[\"tokenizer\"] = AutoTokenizer.from_pretrained(model_name)\n",
    "    row[\"model\"] = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    model_array.append(row)\n",
    " \n",
    "def most_frequent(array):\n",
    "    occurence_count = Counter(array)\n",
    "    return occurence_count.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "def predict(s1, chosen_model):\n",
    "    if not chosen_model:\n",
    "        chosen_model = user_friendly_name_list[0]\n",
    "    scores = {}\n",
    "    full_chosen_model_name = reverse_user_friendly_name[chosen_model]\n",
    "    for row in model_array:\n",
    "        name = row[\"name\"]\n",
    "        if name != full_chosen_model_name:\n",
    "            continue\n",
    "        else:\n",
    "            tokenizer = row[\"tokenizer\"]\n",
    "            model = row[\"model\"]\n",
    "            model_input = tokenizer(*([s1],), padding=True, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                output = model(**model_input)\n",
    "                logits = output[0][0].detach().numpy()\n",
    "                logits = softmax(logits).tolist()\n",
    "                break\n",
    "\n",
    "    def get_description(idx):\n",
    "        description = score_descriptions[idx]\n",
    "        description_pt = score_descriptions_pt[idx]\n",
    "        final_description = description + \"\\n \\n\" + description_pt\n",
    "        return final_description\n",
    "\n",
    "    max_pos = logits.index(max(logits))\n",
    "    markdown_description = get_description(max_pos)\n",
    "    scores = {short_score_descriptions[k]: v for k, v in enumerate(logits)}\n",
    "\n",
    "    # Create a Pandas DataFrame for the classification results\n",
    "    results_df = pd.DataFrame(scores.items(), columns=['Class', 'Probability'])\n",
    "\n",
    "    # Convert the DataFrame to an HTML table\n",
    "    results_html = results_df.to_html(index=False)\n",
    "\n",
    "    # Compute binary classification metrics\n",
    "    true_labels = [1]  # Assuming binary classification, adjust as needed\n",
    "    predicted_labels = [int(max_pos)]  # Assuming binary classification, adjust as needed\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Create a Pandas DataFrame for metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1 Score': [f1]\n",
    "    })\n",
    "\n",
    "    # Convert the metrics DataFrame to an HTML table\n",
    "    metrics_html = metrics_df.to_html(index=False)\n",
    "\n",
    "    return results_html, metrics_html, markdown_description\n",
    "\n",
    "\n",
    "inputs = [\n",
    "    gr.Textbox(label=\"Text\", value=app_examples[0][0]),\n",
    "    gr.Dropdown(label=\"Model\", choices=user_friendly_name_list, value=user_friendly_name_list[0])\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    gr.HTML(label=\"Classification Results\"),\n",
    "    gr.HTML(label=\"Binary Classification Metrics\"),\n",
    "    gr.Markdown(),\n",
    "]\n",
    "\n",
    "# Launch the Gradio app\n",
    "gr.Interface(fn=predict, inputs=inputs, outputs=outputs, title=app_title,\n",
    "             description=app_description,\n",
    "             examples=app_examples,\n",
    "             article=article_string).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tupi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
