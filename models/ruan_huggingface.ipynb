{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from collections import Counter\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datasets_folder = \"../datasets\"\n",
    "file_name = \"tupi_binary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full path to the CSV file\n",
    "csv_file_path = os.path.join(datasets_folder, file_name)\n",
    "\n",
    "# Check if the file exists before attempting to read it\n",
    "if os.path.isfile(csv_file_path):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'text_column' is the column containing the text in your dataset\n",
    "text_column = 'text'\n",
    "\n",
    "# List of terms to exclude\n",
    "exclude_terms = {\n",
    "    'desse', 'aí', 'n', 'https', '@', 'user', 'link', '#', '??', '!!', '_:', '.:', '!:', '? ?', '! !', '_ :', '! :', '? :', 'rt',\n",
    "    'ta', 'tá', 'q', 'pq', 'ter', 'pra', 'vcs', 'todos', 'aí', 'nunca', 'fala', 'ver', 'coisa', 'desse', 'todo', 'quer', 'agora', 'faz',\n",
    "    'n', 'fazer', 'ainda', 'dia', 'pode', 'tudo', 'nao', 'nada', 'vc', 'vai', 'pq', 'por que', 'porque', 'eh', 'ne', 'né', 'é', 'p',\n",
    "    'la', 'lá', 'ai', 'aí', 'to', 'tô','sobre','fez','pois','onde','aqui','pro','dar','ficar','fica','d','[]'\n",
    "}\n",
    "\n",
    "import re\n",
    "\n",
    "# Function to preprocess text by excluding terms\n",
    "def preprocess_text(text):\n",
    "    # Split the text into words using regular expression\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    # Exclude terms in a case-insensitive manner\n",
    "    filtered_words = [word for word in words if word.lower() not in exclude_terms]\n",
    "\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_text\n",
    "\n",
    "# Apply the preprocessing function to the 'text_column' in your DataFrame\n",
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>researcher</th>\n",
       "      <th>year</th>\n",
       "      <th>aggressive</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848623693028e+18</td>\n",
       "      <td>quanto pagava na época da como diz canetada el...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848623777333e+18</td>\n",
       "      <td>os árabes já vão lhes chutar do país</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848960585394e+18</td>\n",
       "      <td>tem que desenhar e explicar o desenho retardad...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65849012716374e+18</td>\n",
       "      <td>chola mais gado e se não quiser pagar mais bar...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65849018793945e+18</td>\n",
       "      <td>michele micheque tinha cartao do bolsonaro bol...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                    id  \\\n",
       "0  twitter  1.65848623693028e+18   \n",
       "1  twitter  1.65848623777333e+18   \n",
       "2  twitter  1.65848960585394e+18   \n",
       "3  twitter  1.65849012716374e+18   \n",
       "4  twitter  1.65849018793945e+18   \n",
       "\n",
       "                                                text      researcher  year  \\\n",
       "0  quanto pagava na época da como diz canetada el...  oliveira et al  2023   \n",
       "1               os árabes já vão lhes chutar do país  oliveira et al  2023   \n",
       "2  tem que desenhar e explicar o desenho retardad...  oliveira et al  2023   \n",
       "3  chola mais gado e se não quiser pagar mais bar...  oliveira et al  2023   \n",
       "4  michele micheque tinha cartao do bolsonaro bol...  oliveira et al  2023   \n",
       "\n",
       "   aggressive  hate  \n",
       "0           1     1  \n",
       "1           1     1  \n",
       "2           1     1  \n",
       "3           1     1  \n",
       "4           1     1  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame size: 43668\n",
      "Train DataFrame size: 34934\n",
      "Test DataFrame size: 8734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "# Assuming 'aggressive' is your target variable\n",
    "\n",
    "# Stratified sampling\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['hate'], random_state=42)\n",
    "\n",
    "# Display the sizes of the resulting DataFrames\n",
    "print(f\"Original DataFrame size: {len(df)}\")\n",
    "print(f\"Train DataFrame size: {len(train_df)}\")\n",
    "print(f\"Test DataFrame size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_string = \"Author: <a href=\\\"https://huggingface.co/ruanchaves\\\">Ruan Chaves Rodrigues</a>. Read more about our <a href=\\\"https://github.com/ruanchaves/eplm\\\">research on the evaluation of Portuguese language models</a>.\"\n",
    "\n",
    "app_title = \"Offensive Language Detection (Detecção de Linguagem Ofensiva)\"\n",
    "\n",
    "app_description = \"\"\"\n",
    "This app detects offensive language in Portuguese text using multiple models. You can either introduce your own sentences by filling in the \"Text\" field or click on one of the examples provided below.\n",
    "(Este aplicativo detecta linguagem ofensiva em texto em português usando vários modelos. Introduza suas próprias frases preenchendo o campo \"Text\", ou clique em um dos exemplos fornecidos abaixo.)\n",
    "\"\"\"\n",
    "\n",
    "app_examples = [[text] for text in test_df['text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    \"ruanchaves/mdeberta-v3-base-hatebr\",\n",
    "    \"ruanchaves/bert-base-portuguese-cased-hatebr\",\n",
    "    \"ruanchaves/bert-large-portuguese-cased-hatebr\",\n",
    "]\n",
    "\n",
    "user_friendly_name = {\n",
    "    \"ruanchaves/mdeberta-v3-base-hatebr\": \"mDeBERTa-v3 (HateBR)\",\n",
    "    \"ruanchaves/bert-base-portuguese-cased-hatebr\": \"BERTimbau base (HateBR)\",\n",
    "    \"ruanchaves/bert-large-portuguese-cased-hatebr\": \"BERTimbau large (HateBR)\",\n",
    "}\n",
    "\n",
    "reverse_user_friendly_name = { v:k for k,v in user_friendly_name.items() }\n",
    "user_friendly_name_list = list(user_friendly_name.values())\n",
    "model_array = []\n",
    "\n",
    "for model_name in model_list:\n",
    "    row = {}\n",
    "    row[\"name\"] = model_name\n",
    "    row[\"tokenizer\"] = AutoTokenizer.from_pretrained(model_name)\n",
    "    row[\"model\"] = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    model_array.append(row)\n",
    "       \n",
    "def predict(s1, chosen_model):\n",
    "    # Find the chosen model in the model_array\n",
    "    selected_model = next((item for item in model_array if item[\"name\"] == chosen_model), None)\n",
    "\n",
    "    if selected_model is None:\n",
    "        raise ValueError(f\"Model '{chosen_model}' not found in model_array.\")\n",
    "\n",
    "    tokenizer = selected_model[\"tokenizer\"]\n",
    "    model = selected_model[\"model\"]\n",
    "    model_input = tokenizer(*([s1],), padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**model_input)\n",
    "        logits = output[0][0].detach().numpy()\n",
    "        probabilities = softmax(logits).tolist()\n",
    "\n",
    "        # Return class prediction (0 or 1) and the probability associated with class 1\n",
    "        class_prediction = logits.argmax()\n",
    "        probability_offensive = probabilities[1]\n",
    "        return class_prediction, probability_offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample = df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>researcher</th>\n",
       "      <th>year</th>\n",
       "      <th>aggressive</th>\n",
       "      <th>hate</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41795</th>\n",
       "      <td>twitter</td>\n",
       "      <td>-</td>\n",
       "      <td>Geraldo Alckmin vs Jair Bolsonaro A esquerda q...</td>\n",
       "      <td>fortuna et al</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19473</th>\n",
       "      <td>twitter</td>\n",
       "      <td>-</td>\n",
       "      <td>vacila não buceta mas eu faço o mesmo só sempr...</td>\n",
       "      <td>leite et al</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25328</th>\n",
       "      <td>twitter</td>\n",
       "      <td>-</td>\n",
       "      <td>um jovem passando vergonha na internet</td>\n",
       "      <td>leite et al</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21857</th>\n",
       "      <td>twitter</td>\n",
       "      <td>-</td>\n",
       "      <td>eu com o chip da claro 馃憥馃従</td>\n",
       "      <td>leite et al</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16749</th>\n",
       "      <td>instagram</td>\n",
       "      <td>-</td>\n",
       "      <td>o lixo veio a tona</td>\n",
       "      <td>vargas et al</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source id                                               text  \\\n",
       "41795    twitter  -  Geraldo Alckmin vs Jair Bolsonaro A esquerda q...   \n",
       "19473    twitter  -  vacila não buceta mas eu faço o mesmo só sempr...   \n",
       "25328    twitter  -             um jovem passando vergonha na internet   \n",
       "21857    twitter  -                        eu com o chip da claro 馃憥馃従   \n",
       "16749  instagram  -                                 o lixo veio a tona   \n",
       "\n",
       "          researcher  year  aggressive  hate  prediction  probability  \n",
       "41795  fortuna et al  2019           0     0         1.0     0.999987  \n",
       "19473    leite et al  2020           1     0         1.0     0.999974  \n",
       "25328    leite et al  2020           0     0         1.0     0.999992  \n",
       "21857    leite et al  2020           0     0         0.0     0.031472  \n",
       "16749   vargas et al  2021           0     0         0.0     0.000012  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a lambda function to apply predict to each row in 'text_column'\n",
    "apply_predict = lambda x: pd.Series(predict(x, \"ruanchaves/bert-large-portuguese-cased-hatebr\"))\n",
    "\n",
    "# Apply the lambda function to the entire 'text_column' and create new columns for results\n",
    "test_df[['prediction', 'probability']] = test_df['text'].apply(apply_predict)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics DataFrame to a CSV file\n",
    "test_df.to_csv('BERTimbau_large_str_20.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tupi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
