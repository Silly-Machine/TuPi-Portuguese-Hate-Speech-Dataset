{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from collections import Counter\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datasets_folder = \"../datasets\"\n",
    "file_name = \"tupi_binary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full path to the CSV file\n",
    "csv_file_path = os.path.join(datasets_folder, file_name)\n",
    "\n",
    "# Check if the file exists before attempting to read it\n",
    "if os.path.isfile(csv_file_path):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_string = \"Author: <a href=\\\"https://huggingface.co/ruanchaves\\\">Ruan Chaves Rodrigues</a>. Read more about our <a href=\\\"https://github.com/ruanchaves/eplm\\\">research on the evaluation of Portuguese language models</a>.\"\n",
    "\n",
    "app_title = \"Offensive Language Detection (Detecção de Linguagem Ofensiva)\"\n",
    "\n",
    "app_description = \"\"\"\n",
    "This app detects offensive language in Portuguese text using multiple models. You can either introduce your own sentences by filling in the \"Text\" field or click on one of the examples provided below.\n",
    "(Este aplicativo detecta linguagem ofensiva em texto em português usando vários modelos. Introduza suas próprias frases preenchendo o campo \"Text\", ou clique em um dos exemplos fornecidos abaixo.)\n",
    "\"\"\"\n",
    "\n",
    "app_examples = [[text] for text in df['text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_textbox_component_description = \"\"\"\n",
    "# This box will display offensive language detection results based on the average score of multiple models.\n",
    "# (Esta caixa exibirá resultados da detecção de linguagem ofensiva com base na pontuação média de vários modelos.)\n",
    "# \"\"\"\n",
    "\n",
    "# output_json_component_description = { \"breakdown\": \"\"\"\n",
    "# This box presents a detailed breakdown of the evaluation for each model.\n",
    "# \"\"\",\n",
    "# \"detalhamento\": \"\"\"\n",
    "# (Esta caixa apresenta um detalhamento da avaliação para cada modelo.)\n",
    "# \"\"\" }\n",
    "\n",
    "# short_score_descriptions = {\n",
    "#    0: \"Not offensive\",\n",
    "#    1: \"Offensive\"\n",
    "# }\n",
    "\n",
    "# score_descriptions = {\n",
    "#     0: \"This text is not offensive.\",\n",
    "#     1: \"This text is offensive.\",\n",
    "# }\n",
    "\n",
    "# score_descriptions_pt = {\n",
    "#     1: \"(Este texto é ofensivo.)\",\n",
    "#     0: \"(Este texto não é ofensivo.)\",\n",
    "# }\n",
    "\n",
    "# model_list = [\n",
    "#     \"ruanchaves/mdeberta-v3-base-hatebr\",\n",
    "#     \"ruanchaves/bert-base-portuguese-cased-hatebr\",\n",
    "#     \"ruanchaves/bert-large-portuguese-cased-hatebr\",\n",
    "# ]\n",
    "\n",
    "# user_friendly_name = {\n",
    "#     \"ruanchaves/mdeberta-v3-base-hatebr\": \"mDeBERTa-v3 (HateBR)\",\n",
    "#     \"ruanchaves/bert-base-portuguese-cased-hatebr\": \"BERTimbau base (HateBR)\",\n",
    "#     \"ruanchaves/bert-large-portuguese-cased-hatebr\": \"BERTimbau large (HateBR)\",\n",
    "# }\n",
    "\n",
    "# reverse_user_friendly_name = { v:k for k,v in user_friendly_name.items() }\n",
    "\n",
    "# user_friendly_name_list = list(user_friendly_name.values())\n",
    "\n",
    "# model_array = []\n",
    "\n",
    "# for model_name in model_list:\n",
    "#     row = {}\n",
    "#     row[\"name\"] = model_name\n",
    "#     row[\"tokenizer\"] = AutoTokenizer.from_pretrained(model_name)\n",
    "#     row[\"model\"] = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "#     model_array.append(row)\n",
    " \n",
    "# def most_frequent(array):\n",
    "#     occurence_count = Counter(array)\n",
    "#     return occurence_count.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "# def predict(s1, chosen_model):\n",
    "#     if not chosen_model:\n",
    "#         chosen_model = user_friendly_name_list[0]\n",
    "#     scores = {}\n",
    "#     full_chosen_model_name = reverse_user_friendly_name[chosen_model]\n",
    "#     for row in model_array:\n",
    "#         name = row[\"name\"]\n",
    "#         if name != full_chosen_model_name:\n",
    "#             continue\n",
    "#         else:\n",
    "#             tokenizer = row[\"tokenizer\"]\n",
    "#             model = row[\"model\"]\n",
    "#             model_input = tokenizer(*([s1],), padding=True, return_tensors=\"pt\")\n",
    "#             with torch.no_grad():\n",
    "#                 output = model(**model_input)\n",
    "#                 logits = output[0][0].detach().numpy()\n",
    "#                 logits = softmax(logits).tolist()\n",
    "#                 break\n",
    "\n",
    "#     def get_description(idx):\n",
    "#         description = score_descriptions[idx]\n",
    "#         description_pt = score_descriptions_pt[idx]\n",
    "#         final_description = description + \"\\n \\n\" + description_pt\n",
    "#         return final_description\n",
    "\n",
    "#     max_pos = logits.index(max(logits))\n",
    "#     markdown_description = get_description(max_pos)\n",
    "#     scores = {short_score_descriptions[k]: v for k, v in enumerate(logits)}\n",
    "\n",
    "#     # Create a Pandas DataFrame for the classification results\n",
    "#     results_df = pd.DataFrame(scores.items(), columns=['Class', 'Probability'])\n",
    "\n",
    "#     # Convert the DataFrame to an HTML table\n",
    "#     results_html = results_df.to_html(index=False)\n",
    "\n",
    "#     # Compute binary classification metrics\n",
    "#     true_labels = [1]  # Assuming binary classification, adjust as needed\n",
    "#     predicted_labels = [int(max_pos)]  # Assuming binary classification, adjust as needed\n",
    "\n",
    "#     accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "#     precision = precision_score(true_labels, predicted_labels)\n",
    "#     recall = recall_score(true_labels, predicted_labels)\n",
    "#     f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "#     # Create a Pandas DataFrame for metrics\n",
    "#     metrics_df = pd.DataFrame({\n",
    "#         'Accuracy': [accuracy],\n",
    "#         'Precision': [precision],\n",
    "#         'Recall': [recall],\n",
    "#         'F1 Score': [f1]\n",
    "#     })\n",
    "\n",
    "#     # Convert the metrics DataFrame to an HTML table\n",
    "#     metrics_html = metrics_df.to_html(index=False)\n",
    "\n",
    "#     return results_html, metrics_html, markdown_description\n",
    "\n",
    "# inputs = [\n",
    "#     gr.Textbox(label=\"Text\", value=app_examples[0][0]),\n",
    "#     gr.Dropdown(label=\"Model\", choices=user_friendly_name_list, value=user_friendly_name_list[0])\n",
    "# ]\n",
    "\n",
    "# outputs = [\n",
    "#     gr.HTML(label=\"Classification Results\"),\n",
    "#     gr.HTML(label=\"Binary Classification Metrics\"),\n",
    "#     gr.Markdown(),\n",
    "# ]\n",
    "\n",
    "# # Launch the Gradio app\n",
    "# gr.Interface(fn=predict, inputs=inputs, outputs=outputs, title=app_title,\n",
    "#              description=app_description,\n",
    "#              examples=app_examples,\n",
    "#              article=article_string).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    \"ruanchaves/mdeberta-v3-base-hatebr\",\n",
    "    \"ruanchaves/bert-base-portuguese-cased-hatebr\",\n",
    "    \"ruanchaves/bert-large-portuguese-cased-hatebr\",\n",
    "]\n",
    "\n",
    "user_friendly_name = {\n",
    "    \"ruanchaves/mdeberta-v3-base-hatebr\": \"mDeBERTa-v3 (HateBR)\",\n",
    "    \"ruanchaves/bert-base-portuguese-cased-hatebr\": \"BERTimbau base (HateBR)\",\n",
    "    \"ruanchaves/bert-large-portuguese-cased-hatebr\": \"BERTimbau large (HateBR)\",\n",
    "}\n",
    "\n",
    "reverse_user_friendly_name = { v:k for k,v in user_friendly_name.items() }\n",
    "user_friendly_name_list = list(user_friendly_name.values())\n",
    "model_array = []\n",
    "\n",
    "for model_name in model_list:\n",
    "    row = {}\n",
    "    row[\"name\"] = model_name\n",
    "    row[\"tokenizer\"] = AutoTokenizer.from_pretrained(model_name)\n",
    "    row[\"model\"] = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    model_array.append(row)\n",
    "       \n",
    "def predict(s1, chosen_model):\n",
    "    tokenizer = model_array[0][\"tokenizer\"]\n",
    "    model = model_array[0][\"model\"]\n",
    "    model_input = tokenizer(*([s1],), padding=True, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**model_input)\n",
    "        logits = output[0][0].detach().numpy()\n",
    "        probabilities = softmax(logits).tolist()\n",
    "\n",
    "        # Return class prediction (0 or 1) and the probability associated with class 1\n",
    "        class_prediction = logits.argmax()\n",
    "        probability_offensive = probabilities[1]\n",
    "        return class_prediction, probability_offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22495/4215088204.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_teste[['prediction','probability']] = df_teste['text'].apply(apply_predict)\n",
      "/tmp/ipykernel_22495/4215088204.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_teste[['prediction','probability']] = df_teste['text'].apply(apply_predict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>researcher</th>\n",
       "      <th>year</th>\n",
       "      <th>aggressive</th>\n",
       "      <th>hate</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848623693028e+18</td>\n",
       "      <td>@user @user @user quanto vc pagava na época da...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848623777333e+18</td>\n",
       "      <td>@user os árabes já vão lhes chutar do país ??</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65848960585394e+18</td>\n",
       "      <td>@user @user @user @user @user tem que desenhar...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65849012716374e+18</td>\n",
       "      <td>@user @user chola mais gado. e se não quiser p...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1.65849018793945e+18</td>\n",
       "      <td>michele micheque nao tinha cartao do bolsonaro...</td>\n",
       "      <td>oliveira et al</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                    id  \\\n",
       "0  twitter  1.65848623693028e+18   \n",
       "1  twitter  1.65848623777333e+18   \n",
       "2  twitter  1.65848960585394e+18   \n",
       "3  twitter  1.65849012716374e+18   \n",
       "4  twitter  1.65849018793945e+18   \n",
       "\n",
       "                                                text      researcher  year  \\\n",
       "0  @user @user @user quanto vc pagava na época da...  oliveira et al  2023   \n",
       "1      @user os árabes já vão lhes chutar do país ??  oliveira et al  2023   \n",
       "2  @user @user @user @user @user tem que desenhar...  oliveira et al  2023   \n",
       "3  @user @user chola mais gado. e se não quiser p...  oliveira et al  2023   \n",
       "4  michele micheque nao tinha cartao do bolsonaro...  oliveira et al  2023   \n",
       "\n",
       "   aggressive  hate  prediction  probability  \n",
       "0           1     1         0.0     0.001359  \n",
       "1           1     1         1.0     0.995865  \n",
       "2           1     1         1.0     0.999969  \n",
       "3           1     1         1.0     0.999975  \n",
       "4           1     1         1.0     0.999946  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a lambda function to apply predict to each row in 'text_column'\n",
    "apply_predict = lambda x: pd.Series(predict(x, \"mDeBERTa-v3 (HateBR)\"))\n",
    "\n",
    "# Apply the lambda function to the entire 'text_column' and create new columns for results\n",
    "df_teste[['prediction','probability']] = df_teste['text'].apply(apply_predict)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tupi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
