{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 09:20:51.764905: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-22 09:20:51.765115: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-22 09:20:51.910987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-22 09:20:52.226295: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 09:20:54.238147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import autokeras as ak\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "#Paths\n",
    "data_path = \"../datasets/tupi_binary.csv\"\n",
    "model_path = \"autokeras_model.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split(test_size=0.2, random_state=42,data_path=data_path):\n",
    "    # Load\n",
    "    df = pd.read_csv(data_path)\n",
    "    # Stratify the train-test split\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[\"hate\"])\n",
    "    # Format\n",
    "    x_train = np.array(df_train[\"text\"])\n",
    "    y_train = np.array(df_train[\"hate\"])\n",
    "    x_test = np.array(df_test[\"text\"])\n",
    "    y_test = np.array(df_test[\"hate\"])\n",
    "    \n",
    "    return x_train , y_train , x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    logits = model.predict(x_test)\n",
    "\n",
    "    # Apply sigmoid to get probabilities\n",
    "    predicted_probabilities = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    y_pred_binary = np.round(predicted_probabilities)\n",
    "    accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "    precision = precision_score(y_test, y_pred_binary)\n",
    "    recall = recall_score(y_test, y_pred_binary)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test, predicted_probabilities)\n",
    "\n",
    "    # Calculate average F1 score\n",
    "    average_f1 = calculate_average_f1(y_test, y_pred_binary)\n",
    "\n",
    "    return accuracy, precision, recall, average_f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_as_pickle(model, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "#\n",
    "def load_model_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 02m 40s]\n",
      "val_loss: 0.2978411912918091\n",
      "\n",
      "Best val_loss So Far: 0.29016774892807007\n",
      "Total elapsed time: 00h 18m 42s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "bert              |vanilla           |text_block_1/block_type\n",
      "0                 |0                 |classification_head_1/dropout\n",
      "adam_weight_decay |adam              |optimizer\n",
      "2e-05             |0.001             |learning_rate\n",
      "512               |None              |text_block_1/bert_block_1/max_sequence_length\n",
      "\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    # Load and split\n",
    "    x_train , y_train , x_test, y_test = load_and_split(data_path=data_path)\n",
    "    # Initialize the text classifier.\n",
    "    clf = ak.TextClassifier(overwrite=True, max_trials=10)  # Experiment with more trials\n",
    "\n",
    "    # Feed the text classifier with training data.\n",
    "    clf.fit(x_train, y_train, epochs=10)  # Experiment with more epochs\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    print(\"Metrics\")\n",
    "    accuracy, precision, recall, average_f1, auc = evaluate_model(clf, x_train, y_train)\n",
    "    print(f\"Evaluation Metrics: Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {average_f1}, AUC: {auc}\")\n",
    "\n",
    "    # Save the best model as a pickle file\n",
    "    save_model_as_pickle(clf.export_model(), model_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "x_train , y_train , x_test, y_test = load_and_split(data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 15 variables whereas the saved optimizer has 1 variables. \n"
     ]
    }
   ],
   "source": [
    "# Load model \n",
    "final_model = load_model_from_pickle(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation - Testing Set\n",
      "273/273 [==============================] - 7s 23ms/step\n",
      "Evaluation Metrics: Accuracy: 0.12033432562399816, Precision: 0.12033432562399816, Recall: 1.0, F1 Score: 0.025850051350193574, AUC: 0.8390817494306073\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation - Testing Set\")\n",
    "accuracy, precision, recall, average_f1, auc = evaluate_model(final_model, x_test, y_test)\n",
    "print(f\"Evaluation Metrics: Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {average_f1}, AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tupi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
